<tool id='NA' name='NA'>
  <command interpreter='bash'>main.sh</command>
  <cancel interpreter='bash'>kill.sh</cancel>
  <inputs>
    <param 
      name='service_novnc_parent_install_dir' 
      label='noVNC installation directory' 
      type='hidden' 
      value='__WORKDIR__/pw/software'  
    ></param>
    <param 
      name='service_novnc_tgz_basename' 
      label='Basename of the novnc tgz file' 
      type='hidden' 
      value='noVNC-1.5.0.tgz'  
    ></param>
    <section name='pwrl_host' type='section' title='Desktop Host' expanded='true'>
      <param 
        name='resource' 
        type='computeResource' 
        label='Service host' 
        hideUserWorkspace='true' 
        help='Resource to host the service'
  	    hideDisconnectedResources='true'
      ></param>
      <param 
        name='nports' 
        label='Number of Ports to Reserve' 
        type='hidden' 
        value='1'  
      ></param>
      <param 
        name='jobschedulertype' 
        type='select' 
        label='Select Controller or SLURM Partition' 
        help='Job will be submitted using SSH or sbatch, respectively'      
        multiple='false'>
          <option value="CONTROLLER" selected="true">Controller</option>
          <option value="SLURM">SLURM Partition</option>
      </param>
      <param 
        name='_sch__dd_account_e__tag_slurmshv2' 
        label='SLURM account' 
        type='dynamicAccountDropdown' 
        help='Account to submit the interactive job' 
        resource='pwrl_host.resource'
        show_if='{"pwrl_host.jobschedulertype":"SLURM","pwrl_host.resource.provider":["slurmshv2","existing"]}'
      ></param>
      <param
        name='_sch__dd_partition_e__tag_slurmshv2'
        type='select'
        label='SLURM partition'
        help='SLURM partition to submit the interactive job' 
        multiple='false'
        show_if='{"pwrl_host.jobschedulertype":"SLURM","pwrl_host.resource.provider":["slurmshv2","existing"]}'
        option='[{"label": "service", "value":"service"}]'
      ></param>
      <param name='qos_tag_slurmshv2'
        label='Quality of Service [QoS]'
        type="dynamicQOSDropdown"
        help="Select a QOS from the drop down menu."
        resource="pwrl_host.resource"
        account="pwrl_host._sch__dd_account_e__tag_slurmshv2"
        partition="pwrl_host._sch__dd_partition_e__tag_slurmshv2"
        dependent="true"
        show_if='{"pwrl_host.jobschedulertype":"SLURM","pwrl_host.resource.provider":["slurmshv2","existing"]}'
      ></param>
      <param 
        name='_sch__dd_partition_e__tag_cloud' 
        label='SLURM partition' 
        type='dynamicPartitionDropdown' 
        resource='pwrl_host.resource'
        help='Partition to submit the interactive job. Leave empty to let SLURM pick the optimal option.' 
        show_if='{"pwrl_host.jobschedulertype":"SLURM","pwrl_host.resource.provider":["gclusterv2", "pclusterv2", "azclusterv2", "aws-slurm", "google-slurm", "azure-slurm"]}'
        optional='true'
        dependent='false'
      ></param>    
      <param 
        name='_sch__dd_time_e_' 
        label='Walltime' 
        type='text'
        value='01:00:00'
        help='e.g. 01:00:00 - Amount of time slurm will honor the interactive session.' 
        show_if='{"pwrl_host.jobschedulertype":"SLURM"}'
      ></param>
      <param 
        name='_sch__dd_nodes_e__tag_slurmshv2' 
        label='Number of nodes' 
        type='hidden' 
        help='Required' 
        value='1'
        show_if='{"pwrl_host.jobschedulertype":"SLURM","pwrl_host.resource.provider":["slurmshv2","existing"]}'
      ></param>
      <param 
        name='_sch__dd_ntasks_e__tag_slurmshv2' 
        label='Number of tasks' 
        type='integer' 
        min="1" 
        max="100" 
        help='--ntasks=value slurm directive' 
        value='1'
        show_if='{"pwrl_host.jobschedulertype":"SLURM","pwrl_host.resource.provider":["slurmshv2","existing"]}'
      ></param>
      <param 
        name='scheduler_directives' 
        label='Scheduler directives' 
        type='text' 
        help='e.g. --mem=1000;--gpus-per-node=1 - Use the semicolon character ; to separate parameters. Do not include the SBATCH keyword.'
        depends_on='pwrl_host.jobschedulertype'
        show_if='SLURM'
        optional='true'
      ></param>
    </section>
    <section name='service' type='section' title='Service' expanded='false'>
      <param 
        name='name_tag_slurmshv2' 
        label='Service' 
        type='hidden' 
        value='turbovnc'
        show_if='{"pwrl_host.resource.provider":["slurmshv2","existing"]}'
      ></param>
      <param 
        name='vnc_type_tag_slurmshv2' 
        label='VNC Server Type' 
        type='hidden' 
        value='turbovnc'
        show_if='{"pwrl_host.resource.provider":["slurmshv2","existing"]}'
      ></param>
      <param 
        name='vnc_exec_tag_slurmshv2' 
        label='Path to vncserver if not in path' 
        type='hidden' 
        value='/opt/TurboVNC/bin/vncserver'
        show_if='{"pwrl_host.resource.provider":["slurmshv2","existing"]}'
      ></param>
      <param 
        name='desktop_tag_slurmshv2' 
        label='Desktop Session' 
        type='hidden' 
        value='mate-session'
        show_if='{"pwrl_host.resource.provider":["slurmshv2","existing"]}'
      ></param>
     <param 
        name='name_tag_cloud' 
        type='select' 
        label='Select remote display protocol' 
        help='Make sure the display protocol is installed in the host!' 
        multiple='false'
        show_if='{"pwrl_host.resource.provider":["gclusterv2", "pclusterv2", "azclusterv2", "aws-slurm", "google-slurm", "azure-slurm"]}'
        value='turbovnc'
        options = "[{'label': 'VNC Server', 'value': 'turbovnc'}, 
        {'label': 'Nice DCV', 'value': 'nicedcv'}, 
        {'label': 'Scyld Cloud Workstation', 'value': 'scw'}]">
      </param>
    </section>
  </inputs>
  <outputs>
  </outputs>
</tool>
